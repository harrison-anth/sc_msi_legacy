##### This Snakemake config file is designed specifically for use with the University of Galway's HPC Lugh #####
##### Author: Harrison Anthony #####
##### Last edited: 6/2/25 #####


jobs: 500
jobname: "{rule}.{jobid}"
#max-jobs-per-second: 200
#max-status-checks-per-second: 200
executor: cluster-generic
show-failed-logs: True
verbose: True
cluster-generic-cancel-cmd: scancel
cores: 1000
cluster-generic-submit-cmd:
  sbatch
    --partition={resources.partition}
    --output=../stdout_files/{rule}.{jobid}
    --error=../error_files/{rule}.{jobid}
    --cpus-per-task={threads}
    --mem={resources.mem}
    --nice=5000
#    --mem-per-cpu={resources.mem_mb}


use-conda: True

#cluster: 'sbatch --partition="normal,highmem" --output="../stdout/{rule}/slurm_%x_%j.out" --error="../error_files/{rule}/slurm_%x_%j.error"'
#note the cluster option does not work with snakemake v8
default-resources:
#    mem_mb: 5000
#    partition: "normal,highmem,MSC,gpu,interactive"
    partition: "highmem,MSC,gpu,normal"
    mem: "15G"

#can add --parsable to sbatch command




#sidenote had to edit lib/python3.12/site-packages/snakemake/executors/slurm/slurm_jobstep.py to include
#call = f"srun -n1 --cpus-per-task={job.threads} --cpu_bind=q {self.format_job_exec(job)}"
#as there is an ongoing issue with older installations of slurm having --cpu_bind versus --cpu-bind
#also this fixes an old srun issue which does not fully utilize the cpus-per-task parallel capacity of clurm
#see the following two git issues for more information:
#https://github.com/snakemake/snakemake/issues/2447
#https://github.com/snakemake/snakemake/issues/2071

